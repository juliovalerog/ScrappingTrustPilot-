{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trustpilot scraping - Trade Republic\n",
        "\n",
        "Este notebook scrapea reseñas de Trustpilot para `www.traderepublic.com` desde la pagina 3 hasta la 10, extrayendo texto y fecha, y guardando el resultado en CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Si falta alguna dependencia, descomenta y ejecuta:\n",
        "# !pip install requests beautifulsoup4 pandas lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from typing import List, Dict\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_URL = \"https://es.trustpilot.com/review/www.traderepublic.com\"\n",
        "START_PAGE = 3\n",
        "END_PAGE = 10\n",
        "OUTPUT_CSV = \"traderepublic_reviews_p3_p10.csv\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": (\n",
        "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "        \"Chrome/122.0.0.0 Safari/537.36\"\n",
        "    ),\n",
        "    \"Accept-Language\": \"es-ES,es;q=0.9,en;q=0.8\",\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_reviews_from_html(html: str) -> List[Dict[str, str]]:\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "    reviews_data = []\n",
        "    review_articles = soup.select(\"article[data-service-review-id]\")\n",
        "\n",
        "    for article in review_articles:\n",
        "        text_elem = article.select_one(\"p[data-service-review-text-typography]\")\n",
        "        date_elem = article.select_one(\"time\")\n",
        "\n",
        "        review_text = text_elem.get_text(\" \", strip=True) if text_elem else \"\"\n",
        "        review_date = date_elem.get(\"datetime\", \"\").strip() if date_elem else \"\"\n",
        "\n",
        "        if review_text:\n",
        "            reviews_data.append({\"review_text\": review_text, \"review_date\": review_date})\n",
        "\n",
        "    return reviews_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_reviews = []\n",
        "\n",
        "for page in range(START_PAGE, END_PAGE + 1):\n",
        "    url = f\"{BASE_URL}?page={page}\"\n",
        "    print(f\"Scrapeando: {url}\")\n",
        "\n",
        "    response = requests.get(url, headers=HEADERS, timeout=30)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    page_reviews = parse_reviews_from_html(response.text)\n",
        "    print(f\"  -> Reseñas encontradas: {len(page_reviews)}\")\n",
        "\n",
        "    all_reviews.extend(page_reviews)\n",
        "    time.sleep(1.5)\n",
        "\n",
        "print(f\"\\nTotal reseñas extraidas: {len(all_reviews)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(all_reviews, columns=[\"review_text\", \"review_date\"])\n",
        "df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
        "print(f\"CSV guardado en: {OUTPUT_CSV}\")\n",
        "df.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
